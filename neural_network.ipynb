{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPRegressor\n",
    "from scipy import sparse\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from numpy import genfromtxt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.load(\"./data/data_prepared.npy\")\n",
    "y = np.array(pd.read_csv('data/data_prepared_labels.csv'))\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.1, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "regressor = MLPRegressor(hidden_layer_sizes=(50, 50, 50, 50), max_iter=100, batch_size=64, verbose=True, validation_fraction=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 67112.80512155\n",
      "Iteration 2, loss = 40624.27713299\n",
      "Iteration 3, loss = 40421.80626930\n",
      "Iteration 4, loss = 40302.70902339\n",
      "Iteration 5, loss = 40178.94714796\n",
      "Iteration 6, loss = 40087.51788838\n",
      "Iteration 7, loss = 40000.71499494\n",
      "Iteration 8, loss = 39909.22446322\n",
      "Iteration 9, loss = 39880.43860420\n",
      "Iteration 10, loss = 39799.52969317\n",
      "Iteration 11, loss = 39766.43587969\n",
      "Iteration 12, loss = 39706.92810934\n",
      "Iteration 13, loss = 39699.53314619\n",
      "Iteration 14, loss = 39580.44631528\n",
      "Iteration 15, loss = 39546.63952932\n",
      "Iteration 16, loss = 39515.81758423\n",
      "Iteration 17, loss = 39454.42614020\n",
      "Iteration 18, loss = 39408.74219216\n",
      "Iteration 19, loss = 39398.48970238\n",
      "Iteration 20, loss = 39356.37767658\n",
      "Iteration 21, loss = 39273.57431124\n",
      "Iteration 22, loss = 39176.28362177\n",
      "Iteration 23, loss = 39073.16283396\n",
      "Iteration 24, loss = 39046.87191016\n",
      "Iteration 25, loss = 38973.92565259\n",
      "Iteration 26, loss = 38941.89508627\n",
      "Iteration 27, loss = 38889.00157962\n",
      "Iteration 28, loss = 38860.99563385\n",
      "Iteration 29, loss = 38808.56233973\n",
      "Iteration 30, loss = 38750.14119389\n",
      "Iteration 31, loss = 38694.28534242\n",
      "Iteration 32, loss = 38701.47239884\n",
      "Iteration 33, loss = 38646.58804600\n",
      "Iteration 34, loss = 38626.24094347\n",
      "Iteration 35, loss = 38597.07231315\n",
      "Iteration 36, loss = 38550.42054966\n",
      "Iteration 37, loss = 38531.74242046\n",
      "Iteration 38, loss = 38509.96558896\n",
      "Iteration 39, loss = 38483.23626735\n",
      "Iteration 40, loss = 38493.38499777\n",
      "Iteration 41, loss = 38453.18602208\n",
      "Iteration 42, loss = 38406.96328131\n",
      "Iteration 43, loss = 38427.28427971\n",
      "Iteration 44, loss = 38401.14853542\n",
      "Iteration 45, loss = 38401.29323066\n",
      "Iteration 46, loss = 38343.97348425\n",
      "Iteration 47, loss = 38348.12298549\n",
      "Iteration 48, loss = 38299.43571805\n",
      "Iteration 49, loss = 38312.84229177\n",
      "Iteration 50, loss = 38263.84571673\n",
      "Iteration 51, loss = 38271.58668199\n",
      "Iteration 52, loss = 38267.61663077\n",
      "Iteration 53, loss = 38245.26901666\n",
      "Iteration 54, loss = 38210.32521078\n",
      "Iteration 55, loss = 38235.49944298\n",
      "Iteration 56, loss = 38236.07772373\n",
      "Iteration 57, loss = 38171.65549496\n",
      "Iteration 58, loss = 38197.81092056\n",
      "Iteration 59, loss = 38183.94563636\n",
      "Iteration 60, loss = 38160.07305675\n",
      "Iteration 61, loss = 38137.39978868\n",
      "Iteration 62, loss = 38137.42414335\n",
      "Iteration 63, loss = 38129.67496954\n",
      "Iteration 64, loss = 38106.29357317\n",
      "Iteration 65, loss = 38083.70130632\n",
      "Iteration 66, loss = 38061.52625659\n",
      "Iteration 67, loss = 38081.63146619\n",
      "Iteration 68, loss = 38039.39879505\n",
      "Iteration 69, loss = 38034.09514265\n",
      "Iteration 70, loss = 38046.07046804\n",
      "Iteration 71, loss = 38035.36386353\n",
      "Iteration 72, loss = 38042.19502484\n",
      "Iteration 73, loss = 37994.70198883\n",
      "Iteration 74, loss = 37979.26295495\n",
      "Iteration 75, loss = 37999.54809852\n",
      "Iteration 76, loss = 37967.90225967\n",
      "Iteration 77, loss = 37969.29221013\n",
      "Iteration 78, loss = 37943.76768110\n",
      "Iteration 79, loss = 37942.83628215\n",
      "Iteration 80, loss = 37957.54733314\n",
      "Iteration 81, loss = 37935.33396154\n",
      "Iteration 82, loss = 37920.76252996\n",
      "Iteration 83, loss = 37938.66948740\n",
      "Iteration 84, loss = 37929.95537545\n",
      "Iteration 85, loss = 37907.09280133\n",
      "Iteration 86, loss = 37939.85201749\n",
      "Iteration 87, loss = 37894.09682522\n",
      "Iteration 88, loss = 37881.24270730\n",
      "Iteration 89, loss = 37877.42095179\n",
      "Iteration 90, loss = 37884.74385774\n",
      "Iteration 91, loss = 37856.11286964\n",
      "Iteration 92, loss = 37861.18846118\n",
      "Iteration 93, loss = 37836.60596703\n",
      "Iteration 94, loss = 37838.37359625\n",
      "Iteration 95, loss = 37841.26518797\n",
      "Iteration 96, loss = 37827.73885219\n",
      "Iteration 97, loss = 37833.24777544\n",
      "Iteration 98, loss = 37809.16859486\n",
      "Iteration 99, loss = 37821.75193529\n",
      "Iteration 100, loss = 37793.79296583\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MLPRegressor(batch_size=64, hidden_layer_sizes=(50, 50, 50, 50), max_iter=100,\n",
       "             verbose=True)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MLPRegressor</label><div class=\"sk-toggleable__content\"><pre>MLPRegressor(batch_size=64, hidden_layer_sizes=(50, 50, 50, 50), max_iter=100,\n",
       "             verbose=True)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "MLPRegressor(batch_size=64, hidden_layer_sizes=(50, 50, 50, 50), max_iter=100,\n",
       "             verbose=True)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regressor.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.45324476841601424\n",
      "257.6353799453256\n"
     ]
    }
   ],
   "source": [
    "predictions = regressor.predict(X_test)\n",
    "print(regressor.score(X_test, y_test))\n",
    "error = np.sqrt((y_test - predictions) ** 2).mean(axis = 0)\n",
    "print(error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trying our regressor on 20 players for which we had at least 2 games\\\n",
    "It can be seen that for players in range 1000-2300 (this range was in our training data) our regressor is doing quite well having more examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 ( number of games: (8,) error: -88.58453825069273, prediction: 2151.6654617493073, real: 2240.25 )\n",
      "1 ( number of games: (8,) error: -230.88213454250626, prediction: 2204.7428654574937, real: 2435.625 )\n",
      "2 ( number of games: (8,) error: -6.44577227807531, prediction: 2300.3042277219247, real: 2306.75 )\n",
      "3 ( number of games: (8,) error: -390.4154536029191, prediction: 2123.959546397081, real: 2514.375 )\n",
      "4 ( number of games: (8,) error: -206.46333742586376, prediction: 2210.4116625741362, real: 2416.875 )\n",
      "5 ( number of games: (7,) error: -122.73686497822882, prediction: 2270.6917064503427, real: 2393.4285714285716 )\n",
      "6 ( number of games: (3,) error: 157.67516682741984, prediction: 1902.6751668274198, real: 1745.0 )\n",
      "7 ( number of games: (7,) error: -71.1744223839737, prediction: 2255.3970061874547, real: 2326.5714285714284 )\n",
      "8 ( number of games: (7,) error: -178.737687539734, prediction: 2102.6908838888376, real: 2281.4285714285716 )\n",
      "9 ( number of games: (7,) error: -124.56921040405723, prediction: 2202.2879324530854, real: 2326.8571428571427 )\n",
      "10 ( number of games: (6,) error: 216.84689641975456, prediction: 1730.0135630864213, real: 1513.1666666666667 )\n",
      "11 ( number of games: (6,) error: -184.64441213838745, prediction: 2194.522254528279, real: 2379.1666666666665 )\n",
      "12 ( number of games: (6,) error: -164.4615010485527, prediction: 2333.5384989514473, real: 2498.0 )\n",
      "13 ( number of games: (6,) error: -77.09571539226545, prediction: 2300.570951274401, real: 2377.6666666666665 )\n",
      "14 ( number of games: (2,) error: 501.51915429724977, prediction: 1323.0191542972498, real: 821.5 )\n",
      "15 ( number of games: (5,) error: -280.01026863646075, prediction: 1911.9897313635392, real: 2192.0 )\n",
      "16 ( number of games: (5,) error: 39.92237051284906, prediction: 1882.122370512849, real: 1842.2 )\n",
      "17 ( number of games: (5,) error: 229.3255656317724, prediction: 1997.5255656317725, real: 1768.2 )\n",
      "19 ( number of games: (5,) error: -414.0083767746994, prediction: 1832.9916232253006, real: 2247.0 )\n",
      "193.97467626765587\n"
     ]
    }
   ],
   "source": [
    "errors = []\n",
    "for x in range(20):\n",
    "    if x == 18:\n",
    "        continue\n",
    "    X_test_2 = np.load(f\"./players/player_prepared_{x}.npy\")\n",
    "    y_test_2 = np.array(pd.read_csv(f'players/player_prepared_labels_{x}.csv'))\n",
    "    predictions = regressor.predict(X_test_2)\n",
    "    errors.append(predictions.mean() - y_test_2.mean())\n",
    "    print(f\"{x} ( number of games: {predictions.shape} error: {predictions.mean() - y_test_2.mean()}, prediction: {predictions.mean()}, real: {y_test_2.mean()} )\")\n",
    "\n",
    "print(np.mean(np.sqrt(np.array(errors) ** 2)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
